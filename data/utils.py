import os
import numpy as np
import torch
from torch.utils.data import Dataset
import random
from torchvision import transforms
from scipy.io import loadmat

from scipy.optimize import curve_fit
from numpy import unwrap
from scipy.signal import butter, filtfilt

from .transform import * #æ­£å¸¸è·‘ç”¨
# from transform import * #debugç”¨
# å…ˆå†™ä¸€ä¸ª CSIåŸºç±»ï¼Œæ•°æ®æ‰€æœ‰çš„æ•°æ®å¤„ç†å®Œ éƒ½è¦é€šè¿‡è¿™ä¸ªå˜æˆdataset
class BaseCSIDataset(Dataset):
    def __init__(self, data, labels, domain=None,descriptation=None, transfrom=False):
        """
        Args:
            data (np.ndarray or torch.Tensor): CSIæ•°æ® (N, ...)
            labels (np.ndarray or torch.Tensor): æ ‡ç­¾ (N,)
            domains_str (str): ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œåˆ—å‡ºæœ‰å“ªäº›æºåŸŸï¼Œæ¯”å¦‚ 'office lab outdoor'
            descriptation (str) ä¸€ä¸ªå­—ç¬¦ä¸² æè¿°æˆ‘è¿™ä¸ªsetå¹²äº†å•¥ 
            transform (bool) è¡¨æ˜æ˜¯å¦ä½¿ç”¨transformation
        """
        super(BaseCSIDataset, self).__init__()
        
        # æ•°æ®è½¬æ¢  
        self.data = torch.tensor(data, dtype=torch.float32) if not isinstance(data, torch.Tensor) else data
        self.labels = torch.tensor(labels, dtype=torch.long) if not isinstance(labels, torch.Tensor) else labels
        self.descriptation=descriptation
        # æ ‡ç­¾é›†åˆï¼ˆå‡åºå»é‡ï¼‰
        self.all_labels = torch.sort(self.labels.unique()).values.tolist()
        # åŸŸå¤„ç†
        self.domains=domain
        self.transform = transfrom
        # æ£€æŸ¥
        assert len(self.data) == len(self.labels), "æ•°æ®å’Œæ ‡ç­¾é•¿åº¦ä¸ä¸€è‡´ï¼"

    def __getitem__(self, index):
        sample = self.data[index]
        if self.transform:
            sample = self.__transform__(sample)
        label = self.labels[index]
        return sample, label  # è¿™é‡Œåªè¿”å›æ ·æœ¬å’Œæ ‡ç­¾ 
    def __len__(self):
        return len(self.data)
    def get_domains(self):
        """è¿”å›å½“å‰åŸŸ"""
        return self.domains
    def get_descriptation(self):
        return self.descriptation
    def get_all_labels(self):
        return self.all_labels  
    def __transform__(self,sample):
        # sample shape [ant,sub,time,amp+phase]
        transform_list = ['no_action', 'scaling_csi']
        return random_applied_trans(sample, transform_list, p=0.5, namespace=None)
        

class WiSDADataset(Dataset):
    def __init__(self, source_img_list, source_label_list):
        self.source_img_list = source_img_list
        self.source_label_list = source_label_list
        self.to_tensor = transforms.ToTensor()
        # self.transform = transforms.Compose([
#     transforms.ToTensor(),
#     transforms.Normalize(mean=[0.485, 0.456, 0.406],
#                          std=[0.229, 0.224, 0.225])  # é€šå¸¸ç”¨äºResNeté¢„è®­ç»ƒæ¨¡å‹
# ])

    def __len__(self):
        return len(self.source_img_list)

    def __getitem__(self, idx):
        # åŠ è½½å›¾åƒ
        img_path = self.source_img_list[idx]
        image = Image.open(img_path).convert('RGB')  # è½¬æˆ RGB æ ¼å¼
        image_np = np.array(image)

        # print(image.size)
        image = self.to_tensor(image)
        assert not torch.isnan(image).any(), f"Image contains NaN values at index {idx}, path: {img_path}"
        # image = self.transform(image)
        
        

        # print(image.shape)

        # åŠ è½½æ ‡ç­¾
        label = self.source_label_list[idx]

        # è½¬æ¢ä¸ºTensor
        label = torch.tensor(label, dtype=torch.long)
        assert not torch.isnan(label).any(), f"Label is NaN at index {idx}, value: {label}"

        return image, label

class SignFiDataset(Dataset):
    def __init__(self, data, labels, domain=None,descriptation=None, transfrom=False,config=None):
        """
        Args:
            data (np.ndarray or torch.Tensor): CSIæ•°æ® (N, ...)
            labels (np.ndarray or torch.Tensor): æ ‡ç­¾ (N,)
            domains_str (str): ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œåˆ—å‡ºæœ‰å“ªäº›æºåŸŸï¼Œæ¯”å¦‚ 'office lab outdoor'
            descriptation (str) ä¸€ä¸ªå­—ç¬¦ä¸² æè¿°æˆ‘è¿™ä¸ªsetå¹²äº†å•¥ 
            transform (bool) è¡¨æ˜æ˜¯å¦ä½¿ç”¨transformation
        """
        super(SignFiDataset, self).__init__()
        
        # æ•°æ®è½¬æ¢  
        # self.data = torch.tensor(data, dtype=torch.float32) if not isinstance(data, torch.Tensor) else data
        self.data=data
        self.config=config
        #æ·»åŠ ä¸Šå½’ä¸€åŒ–é‚£ï¼Ÿ
        # self.data = (self.data - self.data.mean()) / self.data.std()
        self.labels = torch.tensor(labels, dtype=torch.long) if not isinstance(labels, torch.Tensor) else labels
        if self.labels.min() > 0:
            self.labels = self.labels - 1
        self.descriptation=descriptation
        # æ ‡ç­¾é›†åˆï¼ˆå‡åºå»é‡ï¼‰
        self.all_labels = torch.sort(self.labels.unique()).values.tolist()

        # åŸŸå¤„ç†
        self.domains=domain
        self.transform = transfrom
        # æ£€æŸ¥
        assert len(self.data) == len(self.labels), "æ•°æ®å’Œæ ‡ç­¾é•¿åº¦ä¸ä¸€è‡´ï¼"

    def cal_ant_select_coeff(self,csi_data):
        """
            csi_data (np.ndarray): CSI data of shape [A, C, T] 
                                (Antennas, Subcarriers, Timesteps)
        """
        amp = np.abs(csi_data)  # [A, C, T]
        # print("amp type:", type(amp), "amp shape:", amp.shape)
        # Mean and variance over time axis
        mean_amp = np.mean(amp, axis=2)  # [A, C]
        var_amp = np.var(amp, axis=2)    # [A, C]
        # Stability score: mean / var (add epsilon to avoid division by zero)
        stability = mean_amp / (var_amp + 1e-8)  # [A, C]
        # Average over subcarriers
        stability_score = np.mean(stability, axis=1)  # [A]

        return stability_score


    def find_best_interval_by_phase_var(self,csiratio, sampling_rate=200, min_ms=5, max_ms=250, step_ms=5):
        """
        åœ¨[min_ms, max_ms]èŒƒå›´å†…æšä¸¾intervalï¼Œæ‰¾åˆ°ä½¿å¾—ç›¸ä½å·®åˆ†å**æ–¹å·®æœ€å°**çš„interval

        Args:
            csiratio (np.ndarray): å¤æ•°CSIæ¯”å€¼æ•°æ®, shape = [C, T]
            sampling_rate (int): é‡‡æ ·ç‡ï¼ˆHzï¼‰ï¼Œé»˜è®¤ 200Hz
            min_ms (int): æœ€å°intervalï¼ˆå•ä½msï¼‰
            max_ms (int): æœ€å¤§intervalï¼ˆå•ä½msï¼‰
            step_ms (int): æšä¸¾æ­¥é•¿ï¼ˆå•ä½msï¼‰

        Returns:
            best_interval (int): æœ€ä½³intervalï¼ˆå•ä½msï¼‰
            best_diff (np.ndarray): æœ€ä½³intervalå¯¹åº”çš„å·®åˆ†ç»“æœï¼Œshape = [C, M]
        """
        assert csiratio.ndim == 2, "Input csiratio must be [C, T] shape"
        
        C, T = csiratio.shape
        phase = np.angle(csiratio)  # è½¬æ¢ä¸ºç›¸ä½

        best_interval = None
        best_interval_pts=None
        best_diff = None
        min_phase_var = np.inf

        for interval_ms in range(min_ms, max_ms + 1, step_ms):
            interval_pts = int((interval_ms / 1000.0) * sampling_rate)
            if interval_pts <= 0 or T - interval_pts <= 0:
                continue  # è·³è¿‡éæ³•interval

            # ç›¸ä½å·®åˆ†
            diff = phase[:, interval_pts:] - phase[:, :-interval_pts]  # shape [C, T - interval]
            diff = np.unwrap(diff, axis=1)  # è§£ç›¸ä½

            phase_var = np.var(diff)  # æ‰€æœ‰å­è½½æ³¢ã€æ‰€æœ‰æ—¶åˆ»ç»Ÿä¸€è®¡ç®—æ–¹å·®

            if phase_var < min_phase_var:
                min_phase_var = phase_var
                best_interval_pts=interval_pts
                best_interval = interval_ms
                best_diff = diff

        return best_interval_pts, best_diff

    
    def TD_computing_fixed(self,csiratio, interval_ms=80, sampling_rate=200):
        """
        åœ¨ç­‰é—´éš”ï¼ˆå‡åŒ€é‡‡æ ·ï¼‰æƒ…å†µä¸‹è¿›è¡Œå®šé—´éš”å·®åˆ†ã€‚
        
        Args:
            csiratio (np.ndarray): CSI æ¯”å€¼æ•°æ®,shape = [C, T]
            interval_ms (float): å·®åˆ†é—´éš”ï¼Œå•ä½æ¯«ç§’(é»˜è®¤80ms)
            sampling_rate (int): é‡‡æ ·ç‡(Hz),é»˜è®¤200Hz

        Returns:
            np.ndarray: å·®åˆ†ç»“æœï¼Œshape = [C, M]
        """
        C, T = csiratio.shape
        interval_pts = int((interval_ms / 1000.0) * sampling_rate)  # è½¬æ¢æˆç‚¹æ•°

        if interval_pts <= 0:
            raise ValueError("Interval too small for given sampling rate.")

        M = T - interval_pts  # å¯ç”¨çš„å·®åˆ†æ•°é‡
        if M <= 0:
            print("# å¯ç”¨é•¿åº¦ä¸è¶³ä»¥åšå·®åˆ†")
            return []

        # ç›´æ¥åšå·®åˆ†ï¼šcsiratio[:, t+interval] - csiratio[:, t]
        diff = csiratio[:, interval_pts:] - csiratio[:, :-interval_pts]  # [C, M]
        return diff

    def normalize_csi_array(self,data: np.ndarray) -> np.ndarray:
        """
        å¯¹å½¢çŠ¶ä¸º (2, C, T, 2) çš„ CSI æ•°æ®è¿›è¡Œå½’ä¸€åŒ–ï¼š
        - ç¬¬ä¸€ä¸ªç‰¹å¾ï¼ˆæœ€åä¸€ç»´çš„ç¬¬0ä¸ªï¼‰æ˜¯æŒ¯å¹…ï¼Œå½’ä¸€åŒ–åˆ° [0, Ï€]
        - ç¬¬äºŒä¸ªç‰¹å¾æ˜¯ç›¸ä½ï¼Œä¿æŒä¸å˜

        Args:
            data (np.ndarray): è¾“å…¥çš„ CSI æ•°æ®ï¼Œå½¢çŠ¶ä¸º (2, C, T, 2)

        Returns:
            np.ndarray: å½’ä¸€åŒ–åçš„ CSI æ•°æ®ï¼Œå½¢çŠ¶åŒè¾“å…¥
        """
        assert data.shape[-1] == 2, "æœ€åä¸€ä¸ªç»´åº¦å¿…é¡»æ˜¯æŒ¯å¹…å’Œç›¸ä½"

        amp = data[..., 0]  # shape: [2, C, T]
        pha = data[..., 1]  # shape: [2, C, T]

        # å¹…å€¼å½’ä¸€åŒ–åˆ° [0, Ï€]
        amp_min = np.min(amp)
        amp_max = np.max(amp)
        amp_norm = (amp - amp_min) / (amp_max - amp_min + 1e-8)
        amp_norm = np.pi * amp_norm

        # é‡ç»„ä¸º (2, C, T, 2)
        data_norm = np.stack([amp_norm, pha], axis=-1)

        return data_norm



    def remove_phase_offset_single_antenna(self,csi):
        """
        è¾“å…¥ï¼š
            csi: np.ndarray, shape (A, S, T), å¤æ•° CSIï¼Œå…¶ä¸­ï¼š
                A = å¤©çº¿æ•°é‡ï¼ŒS = å­è½½æ³¢æ•°é‡ï¼ŒT = æ—¶é—´å¸§æ•°
        è¾“å‡ºï¼š
            csi_corrected: ç›¸ä½åç§»çº æ­£åçš„å¤æ•° CSIï¼Œshape åŒè¾“å…¥
        """
        
        A, S, T,_ = csi.shape
        # csi = np.array(csi)
        csi_abs = csi[:,:,:,0]
        csi_ang = csi[:,:,:,1]

        # æ„å»ºæ‹Ÿåˆè‡ªå˜é‡ x: [2, A*S]
        idx_tx_subc = np.zeros((2, A, S))
        for a in range(A):
            for s in range(S):
                idx_tx_subc[0, a, s] = (a + 2) / 3 - 2  # å¤©çº¿ç¼–å·ï¼ˆå¯¹é½æ—§ä»£ç ï¼‰
                idx_tx_subc[1, a, s] = -58 + 4 * s      # å­è½½æ³¢ç¼–å·
        idx_tx_subc = idx_tx_subc.reshape(2, -1)  # shape (2, A*S)

        # è·å–ç¬¬ä¸€ä¸ªæ—¶é—´å¸§çš„ç›¸ä½å¹¶unwrap
        phase = csi_ang[..., 0]  # shape: (A, S)
        for a in range(A):
            phase[a, :] = unwrap(phase[a, :])  # æŒ‰å­è½½æ³¢æ–¹å‘å±•å¼€

        # flatten ä¸ºæ‹Ÿåˆç›®æ ‡å€¼
        phase_flat = phase.flatten()

        # å®šä¹‰æ‹Ÿåˆå‡½æ•°
        def func(x, a, b, c):
            return a * x[0] * x[1] + b * x[1] + c

        # æ‹Ÿåˆç³»ç»Ÿæ€§åç§»æ¨¡å‹
        popt, _ = curve_fit(func, idx_tx_subc, phase_flat)

        # ä¼°è®¡å‡ºæ¥çš„ç³»ç»Ÿæ€§åç§»ï¼Œç›¸åŒåº”ç”¨äºæ‰€æœ‰æ—¶é—´å¸§
        phase_offset = func(idx_tx_subc, *popt).reshape(A, S)

        # å»é™¤åç§»
        for t in range(T):
            for a in range(A):
                csi_ang[a, :, t] = unwrap(csi_ang[a, :, t])
                csi_ang[a, :, t] -= phase_offset[a, :]

        # é‡æ„å¤æ•° CSI
        # csi_corrected = csi_abs * np.exp(1j * csi_ang)
        csi_corrected=np.stack([csi_abs, csi_ang], axis=-1)
        def lowpass_filter(data, cutoff=70, fs=200, order=4):  # å‡è®¾é‡‡æ ·ç‡ 1000Hz
            b, a = butter(order, cutoff / (0.5 * fs), btype='low')
            return filtfilt(b, a, data, axis=-1)

        csi_abs = lowpass_filter(csi_abs)     # <-- NEW
        csi_ang = lowpass_filter(csi_ang)     # <-- NEW
        # print(csi_corrected.shape)
        return csi_corrected


    def process_csi_sample_torch(self,sample):
        """
        è¾“å…¥:
            sample: torch.Tensor, shape (3, 30, 200, 2), æœ€åä¸€ç»´æ˜¯ (amp, pha)
        è¾“å‡º:
            processed: torch.Tensor, shape (2, 30, 200, 2)
        """
        assert sample.shape == (3, 30, 200, 2), "è¾“å…¥shapeå¿…é¡»æ˜¯ (3,30,200,2)"

        amp = sample[..., 0]
        pha = sample[..., 1]
        # pha = np.unwrap(pha, axis=1)



        csi_complex = amp * np.exp(1j * pha)  # å¤æ•°å¼ é‡
        stability_score = self.cal_ant_select_coeff(csi_complex)

        all_ants = {0, 1, 2}
        sel_ant1 = int(np.argmax(stability_score))
        ref_ant2 = int(np.argmin(stability_score))
        mid_ant3 = (all_ants - {sel_ant1, ref_ant2}).pop()
        csi_sel1 = csi_complex[sel_ant1,:,:].squeeze()
        csi_ref2 = csi_complex[ref_ant2,:,:].squeeze()
        csi_mid3 = csi_complex[mid_ant3,:,:].squeeze()
        # csi ratio
        csi_ratio1 = csi_sel1 / (csi_ref2 + 1e-8)       # [C, T]
        csi_ratio3 = csi_mid3 / (csi_ref2 + 1e-8)       # [C, T]

        min_csi_len = float('inf')
        max_csi_len = 0
        min_td_len = float('inf')
        max_td_len = 0
        current_len = csi_ratio1.shape[-1]
        min_csi_len = min(min_csi_len, current_len)
        max_csi_len = max(max_csi_len, current_len)


        interval_pts = int((80 / 1000.0) * 200)  # è½¬æ¢æˆç‚¹æ•°

        tdcsi1=self.TD_computing_fixed(csi_ratio1,80)
        # interv1,tdcsi1=self.find_best_interval_by_phase_var(csi_ratio1)

        tdcsi3=self.TD_computing_fixed(csi_ratio3,80)
        # interv3,tdcsi3=self.find_best_interval_by_phase_var(csi_ratio3)

        tdcsi1 = np.pad(tdcsi1, ((0, 0), (0, 16)), mode='constant', constant_values=0)  # (30, 200)
        tdcsi3 = np.pad(tdcsi3, ((0, 0), (0, 16)), mode='constant', constant_values=0)  # (30, 200)
        tdcsi = np.stack([tdcsi1, tdcsi3], axis=0)  # [2, C, T]
        amp_tdcsi = np.abs(tdcsi)   # [2, C, T]
        pha_tdcsi = np.angle(tdcsi)


        # åªåšratio
        # csi_ratio = np.stack([csi_ratio1, csi_ratio3], axis=0)  # [2, C, T]
        # amp=np.abs(csi_ratio)
        # pha=np.angle(csi_ratio)
        # combine_tdcsi = np.stack([amp, pha], axis=-1)



        combine_tdcsi = np.stack([amp_tdcsi, pha_tdcsi], axis=-1)

        # combine_tdcsi=self.normalize_csi_array(combine_tdcsi)

        # combine_tdcsi=self.normalize_csi_array(sample)
    
        return combine_tdcsi

    def __getitem__(self, index):
        sample = self.data[index]
        sample_process=self.remove_phase_offset_single_antenna(sample)
        # print(sample[:,:,:,0].shape)
        # sample_process=np.stack((sample[:,:,:,0],sample[:,:,:,1]),axis=-1)
        sample_tensor = torch.tensor(sample_process, dtype=torch.float32)

        if self.transform:
            sample = self.__transform__(sample)
        label = self.labels[index]
        return sample_tensor, label  # è¿™é‡Œåªè¿”å›æ ·æœ¬å’Œæ ‡ç­¾ 
    def __len__(self):
        return len(self.data)
    def get_domains(self):
        """è¿”å›å½“å‰åŸŸ"""
        return self.domains
    def get_descriptation(self):
        return self.descriptation
    def get_all_labels(self):
        return self.all_labels  
    def __transform__(self,sample):
        # sample shape [ant,sub,time,amp+phase]
        transform_list = ['no_action', 'scaling_csi']
        return random_applied_trans(sample, transform_list, p=0.5, namespace=None)


class WidarDataset(Dataset):
    def __init__(self, file_path_list, label_list, transform=None, preload=False):
        self.file_path_list = file_path_list
        self.label_list = label_list
        self.transform = transform  # å¦‚æœä½ éœ€è¦å¯¹ numpy åš transformï¼Œå¯ä»¥ä¼ å…¥ callable
        self.preload = preload

        if self.preload:
            print("â« æ­£åœ¨é¢„åŠ è½½æ•°æ®åˆ°å†…å­˜...")
            self.data = [np.load(p) for p in self.file_path_list]
            self.labels = [l for l in self.label_list]
            print("âœ… é¢„åŠ è½½å®Œæˆ")

        # æ ‡ç­¾é›†åˆï¼ˆå‡åºå»é‡ï¼‰
        self.all_labels = torch.sort(torch.tensor(self.label_list).unique()).values.tolist()
    def get_all_labels(self):
        return self.all_labels  

    def pad_to_1000_timesteps(self,data):
        T, C1, C2, C3 = data.shape
        if T >= 500:
            return data[:500]  # æˆªæ–­åˆ° 500
        # pad with zeros on time dimension
        pad_width = ((0, 500 - T), (0, 0), (0, 0), (0, 0))
        data_padded = np.pad(data, pad_width, mode='constant', constant_values=0)
        return data_padded

    def get_mat_data(self,file_path):
        #  ç­‰å¾…å®Œå–„ï¼Œå…¶å®å°±æ˜¯replaceæ–¹æ³• æ›¿ä¸€ä¸‹æ–‡ä»¶è·¯å¾„ æŠŠ5ä¸ªnumpyæ•°ç»„è¯»å‡ºæ¥
        # file_path_data1=file_path

        file_name=os.path.basename(file_path)
        parent_path = os.path.dirname(file_path)          # /opt/data/private
        gra_path=os.path.dirname(parent_path)
        file_path_data1=os.path.join(gra_path,"h1divh3",file_name)
        file_path_data2=os.path.join(gra_path,"hivh3",file_name)
        file_path_data3=os.path.join(gra_path,"h1divh2",file_name)
        file_path_data4=os.path.join(gra_path,"h2",file_name)
        file_path_data5=os.path.join(gra_path,"h3",file_name)
        file_path_data6=os.path.join(gra_path,"h1",file_name)

        # ç­‰å¾… æ›¿æ¢è·¯å¾„ 


        h1divh3 = loadmat(file_path_data1)['data1']
        h2divh3 =  loadmat(file_path_data2)['data2']
        h1divh2 =  loadmat(file_path_data3)['data3']
        h2 =  loadmat(file_path_data4)['data4']
        h3=  loadmat(file_path_data5)['data5']
        h1=  loadmat(file_path_data6)['data6']

        return h1divh3,h2divh3,h1divh2,h2,h3,h1

    # ç­‰å¾…å®Œå–„ å…¶å®å°±æ˜¯æ›¿æ¢ä¸ª æ–‡ä»¶åç¼€
    def __len__(self):
        return len(self.file_path_list)
    

    def __getitem__(self, idx):

        is_mat=False
        if self.preload:
            data = self.data[idx]
            label = self.labels[idx]
        else:
            file_path=self.file_path_list[idx]
            file_name=os.path.basename(file_path)
            
            if file_name.endswith('.npy'):
                path = self.file_path_list[idx]
                data = np.load(path)
                label = self.label_list[idx]
            else:
                is_mat=True
                h1divh3,h2divh3,h1divh2,h2,h3,h1=self.get_mat_data(file_path) #è¿™é‡Œçš„æ¯ä¸ªå­—å¦‚å…¶å å½¢çŠ¶éƒ½æ˜¯(60,T) 30ä¸ªå­è½½æ³¢ï¼Œå‰30æ˜¯æŒ¯å¹… å30æ˜¯ç›¸ä½ 

                # TODO éœ€è¦å†™ä¸€ä¸ªé€‰æ‹© å‡½æ•° é€‰æ‹©æˆ‘ä»¬ç”¨ä»€ä¹ˆæ•°æ® æœ€åè¦åˆæˆä¸€ä¸ªdata
                label=self.label_list[idx]
                


        if is_mat==False:
            if self.transform:
                data = self.transform(data)  # å¯¹ numpy åš transformï¼Œæ¯”å¦‚æ ‡å‡†åŒ–ç­‰
            # è¿™é‡Œæ’å€¼å‡½æ•°å¯èƒ½æœ‰é—®é¢˜è¦è¡¥0 
            if data.shape[0]!=500:
                data=self.pad_to_1000_timesteps(data)
            # è½¬æ¢ä¸º Tensor
            data = torch.from_numpy(data).float() #[t, sub, ant, 2]
            label = torch.tensor(label, dtype=torch.long)
            data = data.permute(2, 1, 0, 3) # [ant, sub, time, 2]
            return data, label
        else:
            # ç­‰å¾…å®Œå–„ é—®é¢˜åœ¨äº å½¢çŠ¶ä¸æ˜¯1000äº† åº”è¯¥ç”¨ä»€ä¹ˆæ–¹æ³•ä¸Šä¸‹é‡‡æ · ï¼Ÿï¼Ÿ maybe ä¸Šé‡‡æ ·è¡¥0å°±ok ä¸‹çš„è¯ æˆªå– or paa
            pass
            data = torch.from_numpy(data).float()
            label = torch.tensor(label, dtype=torch.long)
            return data,label

            # 
            
            




class WiGRUNT_dataset(Dataset):
    def __init__(self, source_img_list, source_label_list,transforme=True,preload=False):
        self.source_img_list = source_img_list
        self.source_label_list = source_label_list
        self.to_tensor = transforms.ToTensor()
        if transforme==True:
            self.transform=transform = transforms.Compose([
            transforms.Resize((224, 224)),  # æŒ‡å®šç›®æ ‡å°ºå¯¸ï¼Œå¯æ”¹ä¸ºä½ éœ€è¦çš„å¤§å°
            transforms.ToTensor()
        ])
        self.preload=preload
        if self.preload:
            self.images = [Image.open(p).convert("RGB") for p in self.source_img_list]
            self.labels=[p for p in self.source_label_list]

    def __len__(self):
        return len(self.source_img_list)

    def __getitem__(self, idx):
        # åŠ è½½å›¾åƒ
        img_path=self.source_img_list[idx]
        if self.preload:
            image = self.images[idx]
            label=self.labels[idx]
        else:
            image = Image.open(self.source_img_list[idx]).convert("RGB")
            label = self.source_label_list[idx]

        # print(image.size)
        image = self.transform(image)
        # print(image.shape)

        # åŠ è½½æ ‡ç­¾
        basename=os.path.basename(img_path)
        ges_this=basename.split("_")[1]
        # if int(ges_this) != label:
        #     raise ValueError(f"æ ‡ç­¾æœ‰é—®é¢˜")


        # è½¬æ¢ä¸ºTensor
        label = torch.tensor(label, dtype=torch.long)

        return image, label


# TODO maybeéœ€è¦æ£€æŸ¥ä¸€ä¸‹ label_listå’Œè¯»å–çš„æ˜¯å¦ä¸€æ · ä»¥åŠdfså’Œå›¾ç‰‡è¯»å–æ˜¯å¦æ­£ç¡®
class Wiopen_dataset(Dataset):
    def __init__(self, source_img_list, source_label_list,transforme=True,preload=False):
        self.source_img_list = source_img_list
        
        
        self.source_label_list = source_label_list
        self.to_tensor = transforms.ToTensor()
        if transforme==True:
            self.transform=transform = transforms.Compose([
            transforms.Resize((224, 224)),  # æŒ‡å®šç›®æ ‡å°ºå¯¸ï¼Œå¯æ”¹ä¸ºä½ éœ€è¦çš„å¤§å°
            transforms.ToTensor()
        ])
        self.preload=preload
        if self.preload:
            self.images = [Image.open(p).convert("RGB") for p in self.source_img_list]
            self.labels=[p for p in self.source_label_list]


    def __len__(self):
        return len(self.source_img_list)

    def __getitem__(self, idx):
        # åŠ è½½å›¾åƒ
        img_path=self.source_img_list[idx]
        if self.preload:
            image = self.images[idx]
            label=self.labels[idx]
        else:
            image = Image.open(self.source_img_list[idx]).convert("RGB")
            label = self.source_label_list[idx]
        # img_path_dfs = img_path.replace("data_CSIDA_Wiopen", "data_CSIDA_DFS")
        img_path_dfs = img_path.replace("data_widar_Wiopen", "data_widar_DFS")

        dfs=Image.open(img_path_dfs).convert("RGB")
        

        # print(image.size)
        image = self.transform(image)
        dfs=self.transform(dfs)
        # print(image.shape)

        # åŠ è½½æ ‡ç­¾
        basename=os.path.basename(img_path)
        ges_this=basename.split("_")[1]
        # if int(ges_this) != label:
        #     raise ValueError(f"æ ‡ç­¾æœ‰é—®é¢˜")


        # è½¬æ¢ä¸ºTensor
        label = torch.tensor(label, dtype=torch.long)

        return image, dfs,label,idx


def get_valid_csida_files(root_dir):
    files = os.listdir(root_dir)
    
    valid_prefixes = set()

    for file in files:
        if file.startswith('.'):
            continue  # è·³è¿‡éšè—æ–‡ä»¶

        if not file.endswith('.pkl'):
            continue  # åªå¤„ç†pklæ–‡ä»¶

        # åªè¦å‡ºç°_CSIDAå°±åˆ‡æ‰
        if '_CSIDA' in file:
            prefix = file.split('_CSIDA')[0]
            valid_prefixes.add(prefix)

    valid_prefixes = sorted(list(valid_prefixes))  # æ’åºï¼Œä¿æŒç¨³å®š

    return valid_prefixes

def select_data_with_class(data,label,dataset_name,a=150,select_set=None): #æ ¹æ®ç±»åˆ«ç­›é€‰å‡ºå¯¹åº”çš„dataå’Œlabel
    CSIDA_a=[0,2,3,5] 
    Widar_a=[]

    if dataset_name=='CSIDA':
        indices_in = np.where(np.isin(label, CSIDA_a))[0]
        indices_notin = np.where(~np.isin(label, CSIDA_a))[0]
        # indices = np.isin(label, CSIDA_a)
        # print(indices.shape)
        selected_data_in = data[indices_in]
        selected_label_in = label[indices_in]
        
        selected_data_not_in=data[indices_notin]
        selected_label_not_in=label[indices_notin]
        return selected_data_in, selected_label_in,selected_data_not_in,selected_label_not_in,CSIDA_a
        
        # with open('selected_label.txt', 'w') as f:
        #     for lab in selected_label:
        #         f.write(f"{lab}\n")
    elif dataset_name=='SignFi':
        if select_set==None:
            print(type(label))
            class_set = set(label.tolist())
            selected_set = random.sample(list(class_set), a)
            print(selected_set)
            print(type(selected_set))
            
            indices_in = np.where(np.isin(label, selected_set))[0]
            indices_notin = np.where(~np.isin(label, selected_set))[0]
            selected_data_in = data[indices_in]
            selected_label_in = label[indices_in]
            selected_data_not_in=data[indices_notin]
            selected_label_not_in=label[indices_notin]
            return selected_data_in, selected_label_in,selected_data_not_in,selected_label_not_in , selected_set #è¿”å› é€‰æ‹©çš„æ•°æ®ï¼Œä»¥åŠé€‰æ‹©çš„ç±»åˆ« æ–¹ä¾¿target\
        else:
            # select_set=select_set
            indices_in = np.where(np.isin(label, select_set))[0]
            indices_notin = np.where(~np.isin(label, select_set))[0]
            selected_data_in = data[indices_in]
            selected_label_in = label[indices_in]
            selected_data_not_in=data[indices_notin]
            selected_label_not_in=label[indices_notin]
            return selected_data_in, selected_label_in,selected_data_not_in,selected_label_not_in , select_set    
    elif dataset_name=='Widar3.0':
        if select_set==None:
            print(type(label))
            class_set = set(label.tolist())
            selected_set=random.sample(list(class_set), a)
            indices_in = np.where(np.isin(label, selected_set))[0]
            indices_notin = np.where(~np.isin(label, selected_set))[0]
            selected_data_in = data[indices_in]
            selected_label_in = label[indices_in]
            selected_data_not_in=data[indices_notin]
            selected_label_not_in=label[indices_notin]
            return selected_data_in, selected_label_in,selected_data_not_in,selected_label_not_in , selected_set #è¿”å› é€‰æ‹©çš„æ•°æ®ï¼Œä»¥åŠé€‰æ‹©çš„ç±»åˆ« æ–¹ä¾¿target\
        else:
            indices_in = np.where(np.isin(label, select_set))[0]
            indices_notin = np.where(~np.isin(label, select_set))[0]
            selected_data_in = data[indices_in]
            selected_label_in = label[indices_in]
            selected_data_not_in=data[indices_notin]
            selected_label_not_in=label[indices_notin]
            return selected_data_in, selected_label_in,selected_data_not_in,selected_label_not_in , select_set    
            
    else:
        raise ValueError("Invalid dataset name. Choose either 'CSIDA' or 'Widar'.") 
        

# class FAGes_d2a2dataset(Dataset):
#     def __init__(self, source_img_list, source_label_list,transforme=True,preload=True):
#         self.source_img_list = source_img_list
#         self.source_label_list = source_label_list
#         self.to_tensor = transforms.ToTensor()
#         if transforme==True:
#             self.transform=transform = transforms.Compose([
#             transforms.Resize((224, 224)),  # æŒ‡å®šç›®æ ‡å°ºå¯¸ï¼Œå¯æ”¹ä¸ºä½ éœ€è¦çš„å¤§å°
#             transforms.ToTensor()
#         ])
#         self.preload=preload
#         if self.preload:
#             self.images = []
#             for p in self.source_img_list:
#                 image_a1 = Image.open(p).convert("RGB").convert('L') 
#                 image_a1 = self.transform(image_a1)
#                 img_a2_path = p.replace("data_widar_wiopen", "data_widar_wiopen_h2h3")
#                 image_a2 = Image.open(img_a2_path).convert("RGB").convert('L')  
#                 image_a2 = self.transform(image_a2)
#                 self.images.append(torch.stack([image_a1, image_a2], dim=0).squeeze())  # shape: [2, 224, 224]
#             self.labels=[p for p in self.source_label_list]
#         # æ ‡ç­¾é›†åˆï¼ˆå‡åºå»é‡ï¼‰
#         self.all_labels = torch.sort(torch.unique(torch.tensor(self.source_label_list))).values.tolist()

#     def get_all_labels(self):
#         return self.all_labels  
#     def __len__(self):
#         return len(self.source_img_list)

#     def __getitem__(self, idx):
#         # åŠ è½½å›¾åƒ
#         img_a1_path=self.source_img_list[idx]
#         img_a2_path = img_a1_path.replace("data_widar_wiopen", "data_widar_wiopen_h2h3")

#         if self.preload:
#             image_pair = self.images[idx]
#             label=self.labels[idx]
#         else:
#             image_a1 = Image.open(img_a1_path).convert("RGB")
#             image_a2 = Image.open(img_a2_path).convert("RGB")
#             label = self.source_label_list[idx]
#             image_a1 = image_a1.convert('L') 
#             image_a1= self.transform(image_a1) # [1,224,224]
#             image_a2 = image_a2.convert('L') 
#             image_a2= self.transform(image_a2)
#             image_pair = torch.stack([image_a1, image_a2], dim=0).squeeze()  # shape: [2, 224, 224]
#         label = torch.tensor(label, dtype=torch.long)
#         return image_pair, label

from collections import defaultdict
class FAGes_d2a2dataset(Dataset):
    def __init__(self, source_img_list, source_label_list, transforme=True, preload=False, ratio=None, mode='test'):
        self.source_img_list = source_img_list
        self.source_label_list = source_label_list
        self.preload = preload

        # æ ‡ç­¾é›†åˆï¼ˆå‡åºå»é‡ï¼‰
        # self.all_labels = torch.sort(torch.unique(torch.tensor(self.source_label_list))).tolist()
        self.all_labels = torch.sort(torch.unique(torch.tensor(self.source_label_list))).values.tolist()


        # æ ¹æ® mode å’Œ ratio å†³å®šæ˜¯å¦è¿›è¡ŒæŒ‰ç±»é‡‡æ ·
        if mode == 'train' and ratio is not None:
            # å°†æ ·æœ¬æŒ‰ç±»åˆ«åˆ†ç»„
            label_to_samples = defaultdict(list)
            for img_path, label in zip(self.source_img_list, self.source_label_list):
                label_to_samples[label].append(img_path)

            # æŒ‰æ¯ç±»æ¯”ä¾‹è¿›è¡Œé‡‡æ ·
            new_img_list = []
            new_label_list = []
            for label, samples in label_to_samples.items():
                k = max(1, int(len(samples) * ratio))  # è‡³å°‘ä¿ç•™ä¸€ä¸ª
                selected = random.sample(samples, k)
                # print(selected)
                new_img_list.extend(selected)
                new_label_list.extend([label] * k)

            self.source_img_list = new_img_list
            self.source_label_list = new_label_list

        # åŠ è½½å›¾åƒæ•°æ®
        if self.preload:
            self.images = [np.load(p) for p in self.source_img_list]
            self.labels = self.source_label_list  # ä¸ image_list åŒæ­¥
        else:
            self.labels = self.source_label_list

    def get_all_labels(self):
        return self.all_labels  

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        if self.preload:
            image_pair = self.images[idx]
        else:
            image_pair = np.load(self.source_img_list[idx])
        label = torch.tensor(self.labels[idx], dtype=torch.long)
        return image_pair, label

class d2a2dataset(Dataset):
    def __init__(self, source_img_list, source_label_list,transforme=True,preload=False):
        self.source_img_list = source_img_list
        self.source_label_list = source_label_list
        self.to_tensor = transforms.ToTensor()
        if transforme==True:
            self.transform=transform = transforms.Compose([
            transforms.Resize((224, 224)),  # æŒ‡å®šç›®æ ‡å°ºå¯¸ï¼Œå¯æ”¹ä¸ºä½ éœ€è¦çš„å¤§å°
            transforms.ToTensor()
        ])
        self.preload=preload
        if self.preload:
            self.images = [Image.open(p).convert("RGB") for p in self.source_img_list]
            self.labels=[p for p in self.source_label_list]
        # æ ‡ç­¾é›†åˆï¼ˆå‡åºå»é‡ï¼‰
        self.all_labels = torch.sort(torch.unique(torch.tensor(self.source_label_list))).values.tolist()
    

    def get_all_labels(self):
        return self.all_labels  
    def __len__(self):
        return len(self.source_img_list)

    def __getitem__(self, idx):
        # åŠ è½½å›¾åƒ
        img_a1_path=self.source_img_list[idx]
        img_a2_path = img_a1_path.replace("data_widar_wiopen", "data_widar_wiopen_h2h3")

        if self.preload:
            image = self.images[idx]
            label=self.labels[idx]
        else:
            image_a1 = Image.open(img_a1_path).convert("RGB")
            image_a2 = Image.open(img_a2_path).convert("RGB")

            label = self.source_label_list[idx]

        # print(image.size)
        image_a1= self.transform(image_a1) # [3,224,224]
        image_a2= self.transform(image_a2)

        # åŠ è½½æ ‡ç­¾
        # basename=os.path.basename(img_path)
        # ges_this=basename.split("_")[1]
        # if int(ges_this) != label:
        #     raise ValueError(f"æ ‡ç­¾æœ‰é—®é¢˜")

        # è½¬æ¢ä¸ºTensor
        label = torch.tensor(label, dtype=torch.long)

        return image_a1,image_a2, label

def select_data_with_k_shot(data, label, k):
    """
    æ ¹æ®ç±»åˆ«ç­›é€‰å‡ºæ¯ä¸ªç±»kä¸ªæ ·æœ¬ï¼ˆåšåˆ°ï¼šæ¯ä¸ªç±»åˆ«ç”Ÿæˆä¸€ä¸ªå­å­—å…¸ï¼‰
    """
    print("label.shape:", label.shape)
    #print("labelå†…å®¹:", label)
    
    # ç¬¬ä¸€æ­¥ï¼šæ‰¾åˆ°æ‰€æœ‰ç±»åˆ«
    class_set = set(label.tolist())
    print("æ£€æµ‹åˆ°çš„æ‰€æœ‰ç±»åˆ«æœ‰:", class_set)
    print("æ£€æµ‹åˆ°çš„æ‰€æœ‰ç±»åˆ«æ•°:", len(class_set))
    
    # ç¬¬äºŒæ­¥ï¼šæ¯ä¸ªç±»åˆ«å¯¹åº”ä¸€ä¸ªå­—å…¸ {ç±»åˆ«: [ç´¢å¼•ä»¬]}
    class_indices_list = []

    for c in sorted(class_set):
        indices = np.where(label == c)[0]  # æ‰¾å‡ºå±äºç±»åˆ«cçš„æ ·æœ¬ç´¢å¼•
        indices = indices.tolist()
        class_indices_list.append({c: indices})  # è¿™é‡Œæ”¾åˆ°å­—å…¸é‡Œé¢ï¼
        # print(c, "ç±»åˆ«çš„ç´¢å¼•:", indices)

    #ç¬¬ä¸‰æ­¥,ä»æ¯ä¸ªç±»åˆ«ä¸­éšæœºé€‰æ‹©kä¸ªæ ·æœ¬è¿›è¡Œå‰¥ç¦»  
    k_shot_indices = []      # å­˜æ”¾æ‰€æœ‰k-shotç´¢å¼•
    non_k_shot_indices = []  # å­˜æ”¾æ‰€æœ‰å‰©ä½™çš„ç´¢å¼•
    for item in class_indices_list:
        for cls, indices in item.items():
            
            if len(indices) < k:
                raise ValueError(f"ç±»åˆ«{cls}çš„æ ·æœ¬æ•°é‡åªæœ‰{len(indices)}ä¸ªï¼Œå°‘äºk={k}ï¼Œæ— æ³•å–æ ·ï¼")
            selected = random.sample(indices, k)  # ä»indicesä¸­éšæœºæŒ‘kä¸ª
            not_selected = list(set(indices) - set(selected))  # å‰©ä¸‹çš„

            print(f"ç±»åˆ«{cls}: é€‰ä¸­çš„k-shotæ ·æœ¬ç´¢å¼•: {selected}")
            # print(f"ç±»åˆ«{cls}: å‰©ä½™çš„non-k-shotæ ·æœ¬ç´¢å¼•: {not_selected}")

            k_shot_indices.extend(selected)
            non_k_shot_indices.extend(not_selected)
    
    #print(k_shot_indices)
    #print(non_k_shot_indices)
    data_suppot=data[k_shot_indices]
    label_suppot=label[k_shot_indices]
    data_query=data[non_k_shot_indices]
    label_query=label[non_k_shot_indices]
    # print(data_suppot.shape)
    # print(label_suppot.shape)
    # print(data_query.shape)
    # print(label_query.shape)
    return data_suppot, label_suppot, data_query, label_query

    
# root_dir = "/data0/zzy25/CSIDA/CSIDA/CSI_301/"
# files = get_valid_csida_files(root_dir)
# print(files)


# import numpy as np  
# res=np.load("/data0/zzy25/widar3/no_process_this/20181211_room_room3_Clap_user_user8_location_3_orientation_3_repetition_5.npy")
# print(res.shape)




class visual_dataset(Dataset):
    def __init__(self, source_img_list, source_label_list,transforme=True,preload=False):
        self.source_img_list = source_img_list
        self.source_label_list = source_label_list
        self.to_tensor = transforms.ToTensor()
        if transforme==True:
            self.transform= transforms.Compose([
            transforms.Resize((224, 224)),  # æŒ‡å®šç›®æ ‡å°ºå¯¸ï¼Œå¯æ”¹ä¸ºä½ éœ€è¦çš„å¤§å°
            transforms.ToTensor()
        ])
        self.preload=preload
        if self.preload:
            self.images = [Image.open(p).convert("RGB") for p in self.source_img_list]
            self.labels=[p for p in self.source_label_list]

    def __len__(self):
        return len(self.source_img_list)

    def __getitem__(self, idx):
        # åŠ è½½å›¾åƒ
        img_path=self.source_img_list[idx]
        if self.preload:
            image = self.images[idx]
            label=self.labels[idx]
        else:
            image = Image.open(self.source_img_list[idx]).convert("RGB")
            label = self.source_label_list[idx]

        # print(image.size)
        image = self.transform(image)
        # print(image.shape)

        # åŠ è½½æ ‡ç­¾
        basename=os.path.basename(img_path)
        ges_this=basename.split("_")[1]
        # if int(ges_this) != label:
        #     raise ValueError(f"æ ‡ç­¾æœ‰é—®é¢˜")


        # è½¬æ¢ä¸ºTensor
        label = torch.tensor(label, dtype=torch.long)

        return image, label,img_path


class visual_dataset_1d(Dataset):
    def __init__(self, source_img_list, source_label_list,transforme=True,preload=False):
        self.source_img_list = source_img_list
        self.source_label_list = source_label_list
        self.to_tensor = transforms.ToTensor()
        if transforme==True:
            self.transform=transforms.Compose([
            transforms.Resize((224, 224)),  # æŒ‡å®šç›®æ ‡å°ºå¯¸ï¼Œå¯æ”¹ä¸ºä½ éœ€è¦çš„å¤§å°
            transforms.ToTensor()
        ])
        self.preload=preload
        if self.preload:
            self.images = [Image.open(p).convert("RGB") for p in self.source_img_list]
            self.labels=[p for p in self.source_label_list]

    def __len__(self):
        return len(self.source_img_list)

    def __getitem__(self, idx):
        # åŠ è½½å›¾åƒ
        path=self.source_img_list[idx]
        if self.preload:
            image = self.images[idx]
            label=self.labels[idx]
        else:
            data = np.load(path)
            label = self.source_label_list[idx]

        data = torch.from_numpy(data).float()
        # è½¬æ¢ä¸ºTensor
        label = torch.tensor(label, dtype=torch.long)

        return data, label,path



# TODO åˆ†domain åˆ†domainéœ€è¦self.configå»åš 

class DGDataset(Dataset):
    def __init__(self, file_path_list, label_list, transform=None, preload=False, config=None):
        """
        file_path_list: list of str, æ¯ä¸ªæ ·æœ¬çš„.npyè·¯å¾„
        label_list: list of int, æ¯ä¸ªæ ·æœ¬çš„æ ‡ç­¾
        transform: callable, å¯é€‰ï¼Œå¯¹æ•°æ®åšé¢„å¤„ç†
        preload: bool, å¦‚æœTrueï¼Œé¢„åŠ è½½æ•°æ®åˆ°å†…å­˜
        config: é…ç½®å¯¹è±¡
        """
        self.file_path_list = file_path_list
        self.label_list = label_list
        self.transform = transform
        self.preload = preload
        self.config = config

        # å¤„ç† domainï¼Œå¾—åˆ° domain_label å’Œ domain_counts
        self.domain_label, self.domain_counts = self.parse_domains()
        self.domain_indices = self.build_domain_indices()
        self.label_idx_map = self.get_label_map()
        # print(self.label_idx_map[])
   


        if self.preload:
            print("â« æ­£åœ¨é¢„åŠ è½½æ•°æ®åˆ°å†…å­˜...")
            self.data = [np.load(p) for p in self.file_path_list]
            print("âœ… é¢„åŠ è½½å®Œæˆ")

    def parse_domains(self):
        """
        ä»è·¯å¾„ä¸­æå– room, location, orientation æ‹¼æ¥æˆ domain å­—ç¬¦ä¸²ã€‚
        è¿”å›:
        - domain_label: list of intï¼Œé‡æ˜ å°„åçš„åŸŸç¼–å·
        - domain_counts: dict, æ¯ä¸ªåŸŸç¼–å·çš„æ ·æœ¬æ•°
        """
        raw_domains = []
        # /opt/data/private/ablation_study/data_widar_800/data_tdcsi_dfs/20181109_room_room1_Clap_user_user1_location_1_orientation_1_repetition_1.png

        for file_path in self.file_path_list:
            file_name = os.path.basename(file_path)
            parts = file_name.replace(".npy", "").split("_")

            # æå– room
            if "room" in parts:
                room = parts[parts.index("room") + 1]
            else:
                raise ValueError(f"'room' not found in file name: {file_name}")

            # æå– location
            if "location" in parts:
                location = parts[parts.index("location") + 1]
            else:
                raise ValueError(f"'location' not found in file name: {file_name}")

            # æå– orientation
            if "orientation" in parts:
                orientation = parts[parts.index("orientation") + 1]
            else:
                raise ValueError(f"'orientation' not found in file name: {file_name}")

            # æ‹¼æ¥æˆ domain å­—ç¬¦ä¸²
            domain = f"{room}_location_{location}_orientation_{orientation}"
            raw_domains.append(domain)

        # ğŸŒŸ é‡æ˜ å°„ domain åˆ°è¿ç»­æ•´æ•°ç¼–å·
        unique_domains = sorted(set(raw_domains))
        domain_remap = {domain: i for i, domain in enumerate(unique_domains)}
        self.domainremap_re={i:domain  for i, domain in enumerate(unique_domains)}
        


        domain_label = []
        domain_counts = {i: 0 for i in range(len(unique_domains))}

        for domain in raw_domains:
            mapped = domain_remap[domain]
            domain_label.append(mapped)
            domain_counts[mapped] += 1

        return domain_label, domain_counts

    def build_domain_indices(self):
        """
        æ„å»º domain_indices: æ¯ä¸ªåŸŸç¼–å·å¯¹åº”çš„ç´¢å¼•åˆ—è¡¨
        è¿”å›:
        - dict: {domain_id: [indices]}
        """
        domain_indices = {}
        for idx, domain in enumerate(self.domain_label):
            if domain not in domain_indices:
                domain_indices[domain] = []
            domain_indices[domain].append(idx)
        return domain_indices

    def __len__(self):
        return len(self.file_path_list)

    def __getitem__(self, idx):
        if self.preload:
            data = self.data[idx]
        else:
            data = np.load(self.file_path_list[idx])

        label = self.label_list[idx]
        domain = self.domain_label[idx]

        if self.transform:
            data = self.transform(data)

        data = torch.from_numpy(data).float()
        label = torch.tensor(label, dtype=torch.long)
        domain = torch.tensor(domain, dtype=torch.long)

        return data, label, domain, self.domainremap_re[domain.item()],idx




class LiSADataset(Dataset):
    def __init__(self, file_path_list, label_list, transform=None, preload=False, config=None):
        """
        file_path_list: list of str, æ¯ä¸ªæ ·æœ¬çš„.npyè·¯å¾„
        label_list: list of int, æ¯ä¸ªæ ·æœ¬çš„æ ‡ç­¾
        transform: callable, å¯é€‰ï¼Œå¯¹æ•°æ®åšé¢„å¤„ç†
        preload: bool, å¦‚æœTrueï¼Œé¢„åŠ è½½æ•°æ®åˆ°å†…å­˜
        config: é…ç½®å¯¹è±¡
        """
        self.file_path_list = file_path_list
        self.label_list = label_list
        self.transform = transform
        self.preload = preload
        self.config = config

        # å¤„ç† domainï¼Œå¾—åˆ° domain_label å’Œ domain_counts
        self.domain_label, self.domain_counts = self.parse_domains()
        self.domain_indices = self.build_domain_indices()
        self.label_idx_map = self.get_label_map()
        
        if self.preload:
            print("â« æ­£åœ¨é¢„åŠ è½½æ•°æ®åˆ°å†…å­˜...")
            self.data = [np.load(p) for p in self.file_path_list]
            print("âœ… é¢„åŠ è½½å®Œæˆ")
        
        # æ ‡ç­¾é›†åˆï¼ˆå‡åºå»é‡ï¼‰
        self.all_labels = torch.sort(torch.unique(torch.tensor(self.label_list))).values.tolist()
        # åŸŸæ ‡ç­¾é›†åˆï¼ˆå‡åºå»é‡ï¼‰
        self.all_domain_labels = torch.sort(torch.unique(torch.tensor(self.domain_label))).values.tolist()

        # TODO é’ˆå¯¹åŠç›‘ç£çš„ä¿®æ”¹    
        self.labeled_ratio  = config.ratio
        self.labeled_indices = []
        self.unlabeled_indices = []
        if self.labeled_ratio is not None:
            self._split_labeled_unlabeled()
            self.label_flags = [False] * len(self.file_path_list)
            for idx in self.labeled_indices:
                self.label_flags[idx] = True
        else:
            self.label_flags = [True] * len(self.file_path_list)  # å…¨éƒ¨æœ‰æ ‡ç­¾

    def _split_labeled_unlabeled(self):
        """
        æ ¹æ® labeled_ratio åˆ’åˆ†æœ‰æ ‡ç­¾å’Œæ— æ ‡ç­¾æ ·æœ¬ç´¢å¼•ã€‚
        """
        all_indices = set(range(len(self.file_path_list)))
        labeled_indices_list = []
        
        for label in self.all_labels:
            indices_for_label = self.label_idx_map[label]
            # æ ¹æ®æ¯”ä¾‹è®¡ç®—æœ‰æ ‡ç­¾æ ·æœ¬æ•°ï¼Œå¹¶å–æ•´
            num_labeled = int(len(indices_for_label) * self.labeled_ratio)
            
            # ç¡®ä¿è‡³å°‘æœ‰ä¸€ä¸ªæœ‰æ ‡ç­¾æ ·æœ¬ï¼ˆå¦‚æœæ¯”ä¾‹å¤§äº0ï¼‰
            if self.labeled_ratio > 0 and num_labeled == 0:
                num_labeled = 1

            if len(indices_for_label) < num_labeled:
                print(f"è­¦å‘Šï¼šç±»åˆ« {label} çš„æ ·æœ¬æ•° ({len(indices_for_label)}) å°äº {num_labeled}ã€‚å°†ä½¿ç”¨æ‰€æœ‰æ ·æœ¬ä½œä¸ºæœ‰æ ‡ç­¾æ•°æ®ã€‚")
                labeled_indices_list.extend(indices_for_label)
            else:
                labeled_indices_list.extend(random.sample(indices_for_label, num_labeled))

        self.labeled_indices = labeled_indices_list
        self.unlabeled_indices = list(all_indices - set(self.labeled_indices))
        print(f"âœ… æ•°æ®é›†å·²æ ¹æ®æ¯”ä¾‹åˆ’åˆ†ï¼šæ€»æ ·æœ¬æ•°={len(all_indices)}, æœ‰æ ‡ç­¾æ ·æœ¬æ•°={len(self.labeled_indices)}")

    def parse_domains(self):
        """
        ä»è·¯å¾„ä¸­æå– room, location, orientation æ‹¼æ¥æˆ domain å­—ç¬¦ä¸²ã€‚ 
        è¿”å›:
        - domain_label: list of intï¼Œé‡æ˜ å°„åçš„åŸŸç¼–å·
        - domain_counts: dict, æ¯ä¸ªåŸŸç¼–å·çš„æ ·æœ¬æ•°
        """
        raw_domains = []

        for file_path in self.file_path_list:
            file_name = os.path.basename(file_path)
            parts = file_name.replace(".npy", "").split("_")

            # æå– room
            if 'room' in parts:
                raw_room = parts[parts.index('room') + 1]
                room_num = raw_room.replace('room', '')
                room = f"room_{room_num}"
            else:
                raise ValueError(f"'room' not found in file name: {file_name}")

            # æå– userï¼Œä¿ç•™å‰ç¼€
            if 'user' in parts:
                raw_user = parts[parts.index('user') + 1]
                user_num = raw_user.replace('user', '')
                user = f"user_{user_num}"
            else:
                raise ValueError(f"'user' not found in file name: {file_name}")

            # æå– location
            if 'location' in parts:
                location = parts[parts.index('location') + 1]
            else:
                raise ValueError(f"'location' not found in file name: {file_name}")

            # æå– orientation
            if 'orientation' in parts:
                orientation = parts[parts.index('orientation') + 1]
            else:
                raise ValueError(f"'orientation' not found in file name: {file_name}")

            # æ‹¼æ¥æˆ domain å­—ç¬¦ä¸²
            domain = f"{room}_{user}_location_{location}_orientation_{orientation}"

            raw_domains.append(domain)

        # ğŸŒŸ é‡æ˜ å°„ domain åˆ°è¿ç»­æ•´æ•°ç¼–å·
        unique_domains = sorted(set(raw_domains))
        domain_remap = {domain: i for i, domain in enumerate(unique_domains)}
        self.domain_remap=domain_remap
        self.domainremap_re={i:domain  for i, domain in enumerate(unique_domains)}

        domain_label = []
        domain_counts = {i: 0 for i in range(len(unique_domains))}
  

        for domain in raw_domains:
            mapped = domain_remap[domain]
            domain_label.append(mapped)
            domain_counts[mapped] += 1

        return domain_label, domain_counts


    def build_domain_indices(self):
        """
        æ„å»º domain_indices: æ¯ä¸ªåŸŸç¼–å·å¯¹åº”çš„ç´¢å¼•åˆ—è¡¨
        è¿”å›:
        - dict: {domain_id: [indices]}
        """
        domain_indices = {}
        for idx, domain in enumerate(self.domain_label):
            if domain not in domain_indices:
                domain_indices[domain] = []
            domain_indices[domain].append(idx)
        return domain_indices


    def get_label_map(self):
        """
        æ„å»º label_map:key æ˜¯ç±»åˆ«æ ‡ç­¾ï¼Œvalue æ˜¯è¯¥æ ‡ç­¾å¯¹åº”çš„æ ·æœ¬ç´¢å¼•é›†åˆã€‚
        è¿”å›:
            dict: { label: set(idx1, idx2, ...) }
        """
        label_map = {}
        for idx, label in enumerate(self.label_list):
            label = int(label)
            if label not in label_map:
                label_map[label] = []
            label_map[label].append(idx)

        return label_map

    def get_sample_different_domain_simple(self,y, domain, idx):
        """
        ç®€å•é«˜æ•ˆç‰ˆæœ¬ï¼š
        éšæœºé€‰æ ·æœ¬ç´¢å¼•ï¼Œå¦‚æœ domain ä¸åŒç›´æ¥è¿”å›ã€‚
        æœ€å¤šå°è¯• 30 æ¬¡ï¼Œæ‰¾ä¸åˆ°å°±è¿”å›åŸæ ·æœ¬ã€‚
        """
        max_attempts = 30
        for _ in range(max_attempts):
            idx_choose = np.random.randint(len(self.file_path_list))
            if self.domain_label[idx_choose] != domain.item():
                data = torch.from_numpy(np.load(self.file_path_list[idx_choose])).float()
                label = torch.tensor(self.label_list[idx_choose])
                domain_label = torch.tensor(self.domain_label[idx_choose])
                return data, label, domain_label, idx_choose

        # æ‰¾ä¸åˆ°ï¼Œè¿”å›åŸæ ·æœ¬
        data = torch.from_numpy(np.load(self.file_path_list[idx.item()])).float()
        label = torch.tensor(self.label_list[idx.item()])
        domain_label = torch.tensor(self.domain_label[idx.item()])
        return data, label, domain_label, idx.item()

    def get_sample_different_domain_same_label_simple(self, y, domain, idx):
        """
        æ ¹æ®å½“å‰æ ‡ç­¾ï¼Œåœ¨åŒç±»æ ·æœ¬ä¸­éšæœºæ‰¾ domain ä¸åŒçš„æ ·æœ¬ã€‚
        æœ€å¤šå°è¯• 30 æ¬¡ï¼Œæ‰¾ä¸åˆ°å°±è¿”å›éšæœºæ ·æœ¬ã€‚
        """
        max_attempts = 30
        label = y.item()
        # è·å–è¯¥æ ‡ç­¾å¯¹åº”çš„æ‰€æœ‰ idx é›†åˆï¼Œå¹¶è½¬æˆ list ä»¥ä¾¿éšæœºå–
        candidate_indices = self.label_idx_map[label]
        for _ in range(max_attempts):
            idx_choose = np.random.choice(candidate_indices)
            domain_choose = self.domain_label[idx_choose]
            if domain_choose != domain.item():
                data = torch.from_numpy(np.load(self.file_path_list[idx_choose])).float()
                label_tensor = torch.tensor(self.label_list[idx_choose])
                domain_label_tensor = torch.tensor(domain_choose)
                return data, label_tensor, domain_label_tensor, idx_choose
        # å¦‚æœ30æ¬¡éƒ½æ²¡æ‰¾åˆ°ï¼Œéšä¾¿è¿”å›ä¸€ä¸ª
        idx_choose = np.random.randint(len(self.file_path_list))
        data = torch.from_numpy(np.load(self.file_path_list[idx_choose])).float()
        label_tensor = torch.tensor(self.label_list[idx_choose])
        domain_label_tensor = torch.tensor(self.domain_label[idx_choose])
        return data, label_tensor, domain_label_tensor, idx_choose

    def __len__(self):
        return len(self.file_path_list)

    def __getitem__(self, idx):
        if self.preload:
            data = self.data[idx]
        else:
            data = np.load(self.file_path_list[idx])

        label = self.label_list[idx]
        domain = self.domain_label[idx]

        if self.transform:
            data = self.transform(data)

        data = torch.from_numpy(data).float()
        label = torch.tensor(label, dtype=torch.long)
        domain = torch.tensor(domain, dtype=torch.long)

        # åˆ¤æ–­æ˜¯å¦ä¸ºæœ‰æ ‡ç­¾æ•°æ®
        is_labeled = self.label_flags[idx]
        # å¯¹äºæœ‰æ ‡ç­¾æ•°æ®è¿”å›æ ‡ç­¾ï¼Œå¦åˆ™è¿”å›-1
        if is_labeled:
            return data, label, domain, self.domainremap_re[domain.item()], idx
        else: # å› ä¸ºlabelæ˜¯ä»0å¼€å§‹ï¼Œç›´æ¥ä¹˜-1ä¼šå¯¼è‡´0å˜æˆ0ï¼Œæ‰€ä»¥ä¹˜-1å†å‡1
            return data, -1*label-1, domain, self.domainremap_re[domain.item()], idx
    
    def get_all_labels(self):
        return self.all_labels  
    def get_all_domain_labels(self):
        return self.all_domain_labels

class LiSADataset_CSIDA(Dataset):
    def __init__(self, data, label, domain=None,transform=None, preload=False, config=None):
        """
        file_path_list: list of str, æ¯ä¸ªæ ·æœ¬çš„.npyè·¯å¾„
        label_list: list of int, æ¯ä¸ªæ ·æœ¬çš„æ ‡ç­¾
        transform: callable, å¯é€‰ï¼Œå¯¹æ•°æ®åšé¢„å¤„ç†
        preload: bool, å¦‚æœTrueï¼Œé¢„åŠ è½½æ•°æ®åˆ°å†…å­˜
        config: é…ç½®å¯¹è±¡
        """
        # self.file_path_list = file_path_list
        self.data=data
        self.label = label
        self.domain=domain
        domain_to_id = {domain_str: idx for idx, domain_str in enumerate(sorted(set(self.domain)))}
        self.domain_label = [domain_to_id[d] for d in self.domain]

        self.transform = transform
        self.preload = preload
        self.config = config
        self.label_idx_map = self.get_label_map()

        # æ ‡ç­¾é›†åˆï¼ˆå‡åºå»é‡ï¼‰
        self.all_labels = torch.sort(torch.unique(torch.tensor(self.label))).values.tolist()
        # åŸŸæ ‡ç­¾é›†åˆï¼ˆå‡åºå»é‡ï¼‰
        self.all_domain_labels = torch.sort(torch.unique(torch.tensor(self.domain_label))).values.tolist()    

    def get_label_map(self):
        """
        æ„å»º label_map:
        key æ˜¯ç±»åˆ«æ ‡ç­¾ï¼Œvalue æ˜¯è¯¥æ ‡ç­¾å¯¹åº”çš„æ ·æœ¬ç´¢å¼•é›†åˆã€‚
        
        è¿”å›:
            dict: { label: set(idx1, idx2, ...) }
        """
        label_map = {}

        for idx, label in enumerate(self.label):
            label = int(label)
            if label not in label_map:
                label_map[label] = []
            label_map[label].append(idx)

        return label_map

    def get_sample_different_domain_same_label_simple(self, y, domain, idx):
        """
        æ ¹æ®å½“å‰æ ‡ç­¾ï¼Œåœ¨åŒç±»æ ·æœ¬ä¸­éšæœºæ‰¾ domain ä¸åŒçš„æ ·æœ¬ã€‚
        æœ€å¤šå°è¯• 30 æ¬¡ï¼Œæ‰¾ä¸åˆ°å°±è¿”å›éšæœºæ ·æœ¬ã€‚
        """
        max_attempts = 30
        label = y.item()

        # è·å–è¯¥æ ‡ç­¾å¯¹åº”çš„æ‰€æœ‰ idx é›†åˆï¼Œå¹¶è½¬æˆ list ä»¥ä¾¿éšæœºå–
        candidate_indices = self.label_idx_map[label]

        for _ in range(max_attempts):
            idx_choose = np.random.choice(candidate_indices)
            domain_choose = self.domain_label[idx_choose]

            if domain_choose != domain.item():
                data = torch.from_numpy(self.data[idx_choose]).float()
                label_tensor = torch.tensor(self.label[idx_choose])
                domain_label_tensor = torch.tensor(domain_choose)
                return data, label_tensor, domain_label_tensor, idx_choose

        # å¦‚æœ30æ¬¡éƒ½æ²¡æ‰¾åˆ°ï¼Œéšä¾¿è¿”å›ä¸€ä¸ª
        idx_choose = np.random.randint(len(self.data))
        data = torch.from_numpy(self.data[idx_choose]).float()
        label_tensor = torch.tensor(self.label[idx_choose])
        domain_label_tensor = torch.tensor(self.domain_label[idx_choose])
        return data, label_tensor, domain_label_tensor, idx_choose


    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):

        data=self.data[idx]
        label = self.label[idx]
        domain = self.domain_label[idx]

        if self.transform:
            data = self.transform(data)

        data = torch.from_numpy(data).float()
        label = torch.tensor(label, dtype=torch.long)
        domain = torch.tensor(domain, dtype=torch.long)

        return data, label, domain, domain,idx

    def get_all_labels(self):
        return self.all_labels  
    def get_all_domain_labels(self):
        return self.all_domain_labels


class DARCDataset(Dataset):
    def __init__(self, file_path_list, label_list, cross_domain_type, transform=None, preload=False, config=None):
        """
        file_path_list: list of str, æ¯ä¸ªæ ·æœ¬çš„.npyè·¯å¾„
        label_list: list of int, æ¯ä¸ªæ ·æœ¬çš„æ ‡ç­¾
        transform: callable, å¯é€‰ï¼Œå¯¹æ•°æ®åšé¢„å¤„ç†
        preload: bool, å¦‚æœTrueï¼Œé¢„åŠ è½½æ•°æ®åˆ°å†…å­˜
        config: é…ç½®å¯¹è±¡
        cross_domain_type: str, æŒ‡å®šè·¨åŸŸç±»å‹ï¼ˆroom, user, location
        """
        self.file_path_list = file_path_list
        self.label_list = label_list
        self.transform = transform
        self.preload = preload
        self.config = config
        self.cross_domain_type = cross_domain_type

        # å¤„ç† domainï¼Œå¾—åˆ° domain_label å’Œ domain_counts
        self.domain_label, self.domain_counts = self.parse_domains()
        self.domain_indices = self.build_domain_indices()
        self.label_idx_map = self.get_label_map()
        
        if self.preload:
            print("â« æ­£åœ¨é¢„åŠ è½½æ•°æ®åˆ°å†…å­˜...")
            self.data = [np.load(p) for p in self.file_path_list]
            print("âœ… é¢„åŠ è½½å®Œæˆ")
        
        # æ ‡ç­¾é›†åˆï¼ˆå‡åºå»é‡ï¼‰
        self.all_labels = torch.sort(torch.unique(torch.tensor(self.label_list))).values.tolist()
        # åŸŸæ ‡ç­¾é›†åˆï¼ˆå‡åºå»é‡ï¼‰
        self.all_domain_labels = torch.sort(torch.unique(torch.tensor(self.domain_label))).values.tolist()


    def parse_domains(self):
        """
        ä»è·¯å¾„ä¸­æå– room, location, orientation æ‹¼æ¥æˆ domain å­—ç¬¦ä¸²ã€‚ 
        è¿”å›:
        - domain_label: list of intï¼Œé‡æ˜ å°„åçš„åŸŸç¼–å·
        - domain_counts: dict, æ¯ä¸ªåŸŸç¼–å·çš„æ ·æœ¬æ•°
        """
        raw_domains = []

        for file_path in self.file_path_list:
            file_name = os.path.basename(file_path)
            parts = file_name.replace(".npy", "").split("_")

            # æå– room
            if 'room' in parts:
                raw_room = parts[parts.index('room') + 1]
                room_num = raw_room.replace('room', '')
                room = f"room_{room_num}"
            else:
                raise ValueError(f"'room' not found in file name: {file_name}")

            # æå– userï¼Œä¿ç•™å‰ç¼€
            if 'user' in parts:
                raw_user = parts[parts.index('user') + 1]
                user_num = raw_user.replace('user', '')
                user = f"user_{user_num}"
            else:
                raise ValueError(f"'user' not found in file name: {file_name}")

            # æå– location
            if 'location' in parts:
                location = parts[parts.index('location') + 1]
            else:
                raise ValueError(f"'location' not found in file name: {file_name}")

            # æå– orientation
            if 'orientation' in parts:
                orientation = parts[parts.index('orientation') + 1]
            else:
                raise ValueError(f"'orientation' not found in file name: {file_name}")

            # ğŸ”‘ æ ¹æ® cross_domain_type é€‰æ‹© domain
            if self.cross_domain_type == "room":
                domain = room
            elif self.cross_domain_type == "user":
                domain = user
            elif self.cross_domain_type == "location":
                domain = location
            elif self.cross_domain_type == "orientation":
                domain = orientation
            else:
                raise ValueError(f"Invalid cross_domain_type: {self.cross_domain_type}")

            raw_domains.append(domain)

        # ğŸŒŸ é‡æ˜ å°„ domain â†’ è¿ç»­æ•´æ•°ç¼–å·
        unique_domains = sorted(set(raw_domains))
        domain_remap = {domain: i for i, domain in enumerate(unique_domains)}
        self.domain_remap = domain_remap
        self.domainremap_re = {i: domain for i, domain in enumerate(unique_domains)}

        domain_label = []
        domain_counts = {i: 0 for i in range(len(unique_domains))}
  

        for domain in raw_domains:
            mapped = domain_remap[domain]
            domain_label.append(mapped)
            domain_counts[mapped] += 1

        return domain_label, domain_counts


    def build_domain_indices(self):
        """
        æ”¶é›†æ¯ä¸ªåŸŸçš„æ‰€æœ‰æ ·æœ¬
        æ„å»º domain_indices: æ¯ä¸ªåŸŸç¼–å·å¯¹åº”çš„ç´¢å¼•åˆ—è¡¨
        è¿”å›:
        - dict: {domain_id: [indices]}
        """
        domain_indices = {}
        for idx, domain in enumerate(self.domain_label):
            if domain not in domain_indices:
                domain_indices[domain] = []
            domain_indices[domain].append(idx)
        return domain_indices

    def get_label_map(self):
        """
        å°†æ‰€æœ‰çš„æ ·æœ¬æŒ‰æ ‡ç­¾åˆ†ç»„
        æ„å»º label_map:
        key æ˜¯ç±»åˆ«æ ‡ç­¾ï¼Œvalue æ˜¯è¯¥æ ‡ç­¾å¯¹åº”çš„æ ·æœ¬ç´¢å¼•é›†åˆã€‚
        
        è¿”å›:
            dict: { label: set(idx1, idx2, ...) }
        """
        label_map = {}

        for idx, label in enumerate(self.label_list):
            label = int(label)
            if label not in label_map:
                label_map[label] = []
            label_map[label].append(idx)

        return label_map

    def __len__(self):
        return len(self.file_path_list)

    def __getitem__(self, idx):
        if self.preload:
            data = self.data[idx]
        else:
            data = np.load(self.file_path_list[idx])

        label = self.label_list[idx]
        domain = self.domain_label[idx]

        if self.transform:
            data = self.transform(data)

        data = torch.from_numpy(data).float()
        
        label = torch.tensor(label, dtype=torch.long)
        domain = torch.tensor(domain, dtype=torch.long)

        return data, label, domain, self.domainremap_re[domain.item()],idx
    
    def get_all_labels(self):
        return self.all_labels  
    def get_all_domain_labels(self):
        return self.all_domain_labels